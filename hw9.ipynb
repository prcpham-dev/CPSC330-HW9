{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "251765cc",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"hw9.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33c5b0c-d0f1-40c0-b794-3b3471ac73d2",
   "metadata": {},
   "source": [
    "# CPSC 330 - Applied Machine Learning \n",
    "\n",
    "## Homework 9: Communication\n",
    "\n",
    "**Due date: See the [Calendar](https://htmlpreview.github.io/?https://github.com/UBC-CS/cpsc330/blob/master/docs/calendar.html)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086914c2-5de1-414a-8770-23bef9f312d0",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eced0368-de29-4ea7-9d71-7188d3749f5b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "## Instructions\n",
    "rubric={points}\n",
    "\n",
    "You will earn points for following these instructions and successfully submitting your work on Gradescope.  \n",
    "\n",
    "### Group work instructions\n",
    "\n",
    "**You may work with a partner on this homework and submit your assignment as a group.** Below are some instructions on working as a group.  \n",
    "\n",
    "- The maximum group size is 2.  \n",
    "- Use group work as an opportunity to collaborate and learn new things from each other. \n",
    "- Be respectful to each other and make sure you understand all the concepts in the assignment well. \n",
    "- It's your responsibility to make sure that the assignment is submitted by one of the group members before the deadline. \n",
    "- You can find the instructions on how to do group submission on Gradescope [here](https://help.gradescope.com/article/m5qz2xsnjy-student-add-group-members).\n",
    "- If you would like to use late tokens for the homework, all group members must have the necessary late tokens available. Please note that the late tokens will be counted for all members of the group.   \n",
    "\n",
    "\n",
    "### General submission instructions\n",
    "\n",
    "- Please **read carefully\n",
    "[Use of Generative AI policy](https://ubc-cs.github.io/cpsc330-2025W1/syllabus.html#use-of-generative-ai-in-the-course)** before starting the homework assignment. \n",
    "- **Run all cells before submitting:** Go to `Kernel -> Restart Kernel and Clear All Outputs`, then select `Run -> Run All Cells`. This ensures your notebook runs cleanly from start to finish without errors.\n",
    "  \n",
    "- **Submit your files on Gradescope.**  \n",
    "   - Upload only your `.ipynb` file **with outputs displayed** and any required output files.\n",
    "     \n",
    "   - Do **not** submit other files from your repository.  \n",
    "   - If you need help, see the [Gradescope Student Guide](https://lthub.ubc.ca/guides/gradescope-student-guide/).  \n",
    "- **Check that outputs render properly.**  \n",
    "   - Make sure all plots and outputs appear in your submission.\n",
    "     \n",
    "   - If your `.ipynb` file is too large and doesn't render on Gradescope, also upload a PDF or HTML version so the TAs can view your work.  \n",
    "- **Keep execution order clean.**  \n",
    "   - Execution numbers must start at \"1\" and increase in order.\n",
    "     \n",
    "   - Notebooks without visible outputs may not be graded.  \n",
    "   - Out-of-order or missing execution numbers may result in mark deductions.  \n",
    "- **Follow course submission guidelines:** Review the [CPSC 330 homework instructions](https://ubc-cs.github.io/cpsc330-2025W1/docs/homework_instructions.html) for detailed guidance on completing and submitting assignments. \n",
    "   \n",
    "</div>\n",
    "\n",
    "_Points:_ 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69be5b2d-1854-4c63-bcc6-9b6258b7293a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3ebbf1-5b80-46d7-bd35-7e3a0c94324b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## Exercise 1: Survival analysis\n",
    "<hr>\n",
    "\n",
    "rubric={points}\n",
    "\n",
    "The following questions pertain to the lecture on survival analysis. We'll consider the use case of customer churn analysis.\n",
    "\n",
    "1. What is the problem with simply labeling customers are \"churned\" or \"not churned\" and using standard supervised learning techniques?\n",
    "2. Consider customer A who just joined last week vs. customer B who has been with the service for a year. Who do you expect will leave the service first: probably customer A, probably customer B, or we don't have enough information to answer? Briefly explain your answer. \n",
    "3. If a customer's survival function is almost flat during a certain period, how do we interpret that?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d15ee3-57f3-4823-a7be-debedda8b3c9",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_1\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10665422",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "source": [
    "1. Because that does not account for the time dimension and ignores sensoring. A customer churn after 5 days and one after a few years both get the same \"churned\" lable. A customer who is still active till today still can churned in the future with a right-censored. Using suprevised learning does not handle the right-censored problem. Only survival analysis can use time till event and censoring to predict the outcome of each case.\n",
    "\n",
    "2. Churn often happen really early so someone join last week would be more likely to churned. While someone has already stayed for a year, they would more likely to stay more.\n",
    "\n",
    "3. A flat survival function means that, during that time range, the probability of a customer staying is not decreasing, so the chance of leaving is constant during that period."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dab5740-ae46-4efd-a08e-bf4ae9482701",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed594c68-91c3-45d9-baec-6ac38a02c971",
   "metadata": {},
   "source": [
    "## Exercise 2: Communication\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5767926d-c17d-4a93-b59a-7242a4c76ff0",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### 2.1 Blog post \n",
    "rubric={points}\n",
    "\n",
    "Write up your analysis from hw5 or any other assignment or your side project on machine learning in a \"blog post\" or report format. It's fine if you just write it here in this notebook. Alternatively, you can publish your blog post publicly and include a link here. (See exercise 4.3.) The target audience for your blog post is someone like yourself right before you took this course. They don't necessarily have ML knowledge, but they have a solid foundation in technical matters. The post should focus on explaining **your results and what you did** in a way that's understandable to such a person, **not** a lesson trying to teach someone about machine learning. Again: focus on the results and why they are interesting; avoid pedagogical content.\n",
    "\n",
    "Your post must include the following elements (not necessarily in this order):\n",
    "\n",
    "- Description of the problem/decision.\n",
    "- Description of the dataset (the raw data and/or some EDA).\n",
    "- Description of the model.\n",
    "- Description your results, both quantitatively and qualitatively. Make sure to refer to the original problem/decision.\n",
    "- A section on caveats, describing at least 3 reasons why your results might be incorrect, misleading, overconfident, or otherwise problematic. Make reference to your specific dataset, model, approach, etc. To check that your reasons are specific enough, make sure they would not make sense, if left unchanged, to most students' submissions; for example, do not just say \"overfitting\" without explaining why you might be worried about overfitting in your specific case.\n",
    "- At least 3 visualizations. These visualizations must be embedded/interwoven into the text, not pasted at the end. The text must refer directly to each visualization. For example \"as shown below\" or \"the figure demonstrates\" or \"take a look at Figure 1\", etc. It is **not** sufficient to put a visualization in without referring to it directly.\n",
    "\n",
    "A reasonable length for your entire post would be **800 words**. The maximum allowed is **1000 words**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6169eefb-18a8-4e13-b7ca-1b3539a79215",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### Example blog posts\n",
    "\n",
    "Here are a few optional examples if you‚Äôd like inspiration. You don‚Äôt need to read them in full; instead, skim one and pay attention to:\n",
    "\n",
    "- how they introduce the question/problem,\n",
    "\n",
    "- how they describe the data and show a few key plots,\n",
    "\n",
    "- how they briefly describe the model without turning it into a tutorial, and\n",
    "\n",
    "- how they discuss results and limitations in plain language.\n",
    "\n",
    "**Examples**\n",
    "\n",
    "- [Will your Kickstarter Project be successful? | A simple analysis to help you predict better!!!](https://blog.goodaudience.com/kickstarter-projects-prediction-of-state-steps-for-a-beginner-analysis-f4630a50b7fe) (GoodAudience)\n",
    "- [My Little Markov Model - Now Tweeting New Taylor Swift Lyrics](https://ubc-mds.github.io/2022-12-01-my-little-markov-model/) (UBC MDS)\n",
    "- [What's for dinner? Predicting customer order probabilities](https://ubc-mds.github.io/2019-07-26-predicting-customer-probabilities/) (UBC MDS)\n",
    "\n",
    "**Additional inspiration**\n",
    "\n",
    "These are interviews with Kaggle competition winners. They aren‚Äôt blog posts, but they offer insight into how people articulate data, modeling decisions, and results:\n",
    "\n",
    "- [Instacart Market Basket Analysis](https://medium.com/kaggle-blog/instacart-market-basket-analysis-feda2700cded)\n",
    "- [Winner Interview with Shivam Bansal | Data Science for Good Challenge: City of Los Angeles](https://medium.com/kaggle-blog/winner-interview-with-shivam-bansal-data-science-for-good-challenge-city-of-los-angeles-3294c0ed1fb2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfdd094-eeb6-4f00-a3bc-5a6105eedb12",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### A note on plagiarism\n",
    "\n",
    "You may **NOT** include text or visualizations that were not written/created by you. If you are in any doubt as to what constitutes plagiarism, please just ask. For more information see the [UBC Academic Misconduct policies](https://academicintegrity.ubc.ca/regulation-process/academic-misconduct/). Please don't copy this from somewhere or ask Generative AI to write it for you üôè. Please carefully read [the Use of Generative AI policy](https://ubc-cs.github.io/cpsc330-2025W1/syllabus.html#use-of-generative-ai-in-the-course) before writing your blogpost. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a33abb-71b9-4308-b7a1-8a2d75a5afc6",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_2_1\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 26"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4052395d-a695-4063-97b6-46c4e13016d8",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "### Predicting Credit Card Defaults: What I Learned From Building a Model\n",
    "\n",
    "#### Problem: who is going to default?\n",
    "The goal of my project was to help a bank estimate which credit card clients are likely to default on their payment next month. This is a classic decision problem: if we can find high risk customers early, the bank could lower their credit limits, reach out proactively, or adjust its risk exposure.\n",
    "\n",
    "treated this as a binary classification problem, where the target has only two options, represented by default.payment.next.month (1 = default, 0 = no default).\n",
    "\n",
    "#### The dataset and basic exploration\n",
    "I used ‚ÄúDefault of Credit Card Clients‚Äù dataset. Each row is a client, and the columns describe things like:\n",
    "\n",
    "- Demographics: AGE, SEX, MARRIAGE, EDUCATION\n",
    "- Credit limit: LIMIT_BAL\n",
    "- Payment history: PAY_0 to PAY_6 (repayment status in the last 6 months)\n",
    "- Bills and payments: BILL_AMT1‚ÄìBILL_AMT6, PAY_AMT1‚ÄìPAY_AMT6\n",
    "- In total, there are 30,000 clients and 24 features, plus the target. As part of my initial exploratory data analysis (EDA), I looked at the distributions of the main numerical features.\n",
    "\n",
    "From this, a few things stood out:\n",
    "- Many financial variables are heavily skewed (having more vaules on the left of the graph than the right).\n",
    "- Some customers have very high credit limits and very large bills, which could dominate other smaler number.\n",
    "- Payment status variables (PAY_*) have a few common values (like 0, -1, 1, 2), reflecting categories, not continuous counts.\n",
    "\n",
    "Some columns in the data have very big numbers and some have small numbers. To stop the big numbers from unfairly influencing the model, I used a tool called StandardScaler. It simply adjusts all the numbers so they are on a similar scale before training the model.\n",
    "\n",
    "#### Models I tried\n",
    "I compared several supervised learning models, which means they learn from examples where we already know the correct answer. In our case, each example is a past customer with their information (age, credit limit, payment history, etc.) and a label saying whether they did or did not default. The model then looks for patterns that connect the inputs (customer info) to the output (default or not), so that it can make predictions for new customers it hasn‚Äôt seen before.\n",
    "\n",
    "A simple everyday example is email spam detection: the system is given many emails labeled as ‚Äúspam‚Äù or ‚Äúnot spam,‚Äù learns the patterns, and then uses those patterns to decide whether a new email is spam. Here, instead of ‚Äúspam vs not spam,‚Äù we‚Äôre predicting ‚Äúdefault vs no default.‚Äù\n",
    "\n",
    "The models we will be using are\n",
    "\n",
    "- DummyClassifier\n",
    "- Logistic Regression\n",
    "- K-Nearest Neighbours\n",
    "- Decision Tree\n",
    "- Random Forest\n",
    "\n",
    "I split the data into two parts: 70% for training and 30% for testing.\n",
    "\n",
    "The training set is what the model learns from. It sees these customers and their outcomes (default or not) and tries to find patterns.\n",
    "The test set is kept aside and not shown to the model during training. After the model is trained, I use this test set to see how well it works on new, unseen customers. This gives a more honest check of how the model might perform in the real world.\n",
    "\n",
    "For each model, I also used cross-validation on the training set. This means I repeatedly split the training data into several smaller train and test sets , train the model on part of the data, and check how well it does on the remaining part, then average the results. This helps get a more reliable estimate and reduces the chance that my results are just due to being ‚Äúlucky‚Äù or ‚Äúunlucky‚Äù when splitting of the data.\n",
    "\n",
    "#### Result\n",
    "Cross validation accuracy is the curracy we got from doing cross-validation on the train data\n",
    "\n",
    "And, what we will be looking at is test accuracy. This measures how well the model performs on new, unseen data. In other words, how it is likely to preform in real life\n",
    "\n",
    "The Random Forest model achieved the best overall accuracy of 82.3%. With almost no overfitting.\n",
    "\n",
    "Overfitting happens when a model learns the training data too well, so it looks great on the training set but does poorly on new data. It‚Äôs like memorizing answers for a practice exam instead of actually understanding the material.\n",
    "\n",
    "In my case, the Random Forest‚Äôs performance on the training data and on the test data were very similar, which suggests it is not just memorizing and is likely to generalize better to new customers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59667c9-db6a-4c12-a556-5b9815ef3564",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### 2.2 Effective communication technique\n",
    "rubric={points}\n",
    "\n",
    "Describe one effective communication technique that you used in your post, or an aspect of the post that you are particularly satisfied with. (Max 3 sentences.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea91029-9c18-4d0d-a916-78b391df9435",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_2_2\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ea9c37-34c9-4b3e-a2df-e00cedd3e8ae",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "Communication technique I used in my post: \n",
    "- Explaining technical ideas in plain, everyday language. For example, exaplining training and test set, cross validation and overfitting. \n",
    "- Using example or analogy for concept like supervise training model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56965b8c-9f4d-4a68-be4c-2a745dcf9989",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### (optional, not for marks) 2.3\n",
    "\n",
    "Publish your blog post from 1.1 publicly using a tool like [Quarto](https://quarto.org/), or somewhere like medium.com, and paste a link here. Be sure to pick a tool in which code and code output look reasonable. This link could be a useful line on your resume!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21a1f7b-8904-4f84-b8e7-592041eec55b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Solution_2_3\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a55e63-38cb-4e36-867f-0261d1c583de",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "https://medium.com/@climatecontext279/predicting-credit-card-defaults-what-i-learned-from-building-a-model-991d0a81a826?postPublishedType=initial\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04cefc8e-cf76-4c27-9aa6-c560cbc0fc2b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## Exercise 3: Your takeaway from the course \n",
    "rubric={points}\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "- Reflect on your journey through this course. Please identify and elaborate on at least three key concepts or experiences where you had an \"aha\" moment. How would you use the concepts learned in this course in your personal projects or how would you approach your past projects differently based on the insights gained in this course? We encourage you to dig deep and share your genuine reflections.\n",
    "\n",
    "> Please write thoughtful answers. We are looking forward to reading them üôÇ. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99c85ae-6088-48cd-a23f-a7bc4e1b3f49",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    \n",
    "Solution_3\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fb9e2f-a2d2-4f56-9fb4-c91492e4801b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "- How fine tuning and hyperparameters work. For example, before, I only knew that if we changed the number of neighbors, we can change the accuracy. But now I know there are built in functions that can do this for you. There‚Äôs no need for a for loop and manually typing in the model and each process on notebook. Instead, there‚Äôs a built in process to create a pipeline for preprocessing, fine tuning, cross validation, and evaluating the model, not just calling .fit() and .score().\n",
    "- Time series also something new I learn in this course. I know how time works on some data but never really learn how to deal with them. On top of that, time series opening up about how data can realated to each other that I can still use to learn. For example, instead of time, we can take data from a mining facility and depth of the drills will be similar to time.\n",
    "- Gridsearch and randomsearch also helps me with instead of kust manually choosing number from 1 to 100 maybe, we can create a range for it to search. Or if we are dealing with heavy models like RandomForest, we can do RandomSearch which preform almost the same while keeping the running time fast and can explore unqiue area we did not know.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4e160c-d947-4123-8e67-fa3c89c9aa8f",
   "metadata": {},
   "source": [
    "### Congratulations üëèüëè\n",
    "\n",
    "That's all for the assignments! Congratulations on finishing all homework assignments! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f3bee4-0171-4465-838f-e5ac8a943e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image(\"img/eva-congrats.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
